---
title: Mysterious Stones Results Discussion
author: Bonan Zhao
date: Nov 2, 2020
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float:
      collapsed: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(results = T)
```

```{r prep, include=FALSE}
# Packages & data
library(dplyr)
library(ggplot2)

labels<-read.csv('../data/responses/labelled.csv', stringsAsFactors=F)
```

```{r echo=FALSE}
# Format data
labels<-labels %>%
  filter(rule_like==1) %>%
  mutate(fix=if_else(condition %in% c('A1', 'A3'), 'A', 'R'),
         fix_cond=if_else(condition %in% c('A1', 'A3'), 'Fix A', 'Fix R'),
         rule_change=if_else(condition %in% c('A1','A2'), 'edge', 'shade'),
         rule_change_cond=if_else(condition %in% c('A1','A2'), 'Rule edge(A)', 'Rule shade(A)')) %>%
  mutate(rule_type=factor(rule_type, 
           levels=c(
             'true_relative', 'true_constant', 'vague',
             'sophisticated', 'partial', 'incompatible')),
         categorization=factor(categorization, levels=c('A', 'R', '')))

```


# Free responses analysis

Re-coded the free responses on 102 valid data entries 
(total data is 163, excluded 62 responses because of non-task related responses).

Coding includes three aspects:

- **Rule type**: what type of causal rule does a free response belong to?
- **Categorization**: does the free response categorizes learning observations? 
  If so, is the categorization on Active stone, Inactive stone, or both?
- **Feature sources**: when describing the feature changes of the result stone M,
  does the rule reference it to a constant change or a particular source?

## Rule Types

### Definition

- **Incompatible**: conflict with learning data
- **Partial**: explicitly describe part of the learning data (usually just one data point), leave the rest unmentioned
- **True_constant**: get the true rule with setting one M feature to a constant value
- **True_relative**: get the true rule where both M features are relative to the Active (A) or Inactive (R) stone
- **Vague**: get part of the true rules, leave the rest unmentioned; is broad about feature changes: darkens, changes, become a new shape etc (get finer analysis on these rules later)
- **Sophisticated**: over sophisticated than the true rules while also being true

```{r echo=FALSE}
ggplot(labels, aes(x=rule_change_cond, fill=rule_type)) + 
  geom_bar(stat="count", position="fill") +
  facet_grid(~fix_cond, switch = "x", scales = "free_x", space = "free_x") +
  theme(panel.spacing = unit(0, "lines"), 
        strip.background = element_blank(),
        strip.placement = "outside") +
  labs(x='', y='', title='Rule type') +
  scale_fill_brewer(palette="Paired")
```

```{r}
glm(rule_type=='true_constant' ~ fix + rule_change, 
    data=labels, family='binomial') %>% summary()

glm(rule_type=='true_constant'~ fix + rule_change + fix * rule_change, 
    data=labels, family='binomial') %>% summary()
```

**No effects for other rule types.**

### Classify rule types

- **True_rules**: true_relative, true_constant
- **Other_compatible**: vague, partial,sophisticated
- **Incompatible**

```{r echo=FALSE}
labels <- labels %>%
  mutate(rule_type=as.character(rule_type)) %>%
  mutate(rule_cat=case_when(
    grepl('true', rule_type) ~ 'true_rules',
    rule_type=='incompatible' ~ rule_type,
    TRUE ~ 'other'
  )) %>%
  mutate(rule_cat=factor(rule_cat, levels=c('true_rules', 'other', 'incompatible')))

ggplot(labels, aes(x=rule_change_cond, fill=rule_cat)) + 
  geom_bar(stat="count", position="fill") +
  facet_grid(~fix_cond, switch = "x", scales = "free_x", space = "free_x") +
  theme(panel.spacing = unit(0, "lines"), 
        strip.background = element_blank(),
        strip.placement = "outside") +
  labs(x='', y='', title='Rule type') +
  scale_fill_brewer(palette="Paired")
```

#### GLMs
```{r}
glm(rule_cat=='true_rules' ~ fix + rule_change, 
    data=labels, family='binomial') %>% summary()

glm(rule_cat=='true_rules' ~ fix + rule_change + fix * rule_change, 
    data=labels, family='binomial') %>% summary()

glm(rule_cat=='other' ~ fix + rule_change, 
    data=labels, family='binomial') %>% summary()

glm(rule_cat=='other' ~ fix + rule_change + fix * rule_change, 
    data=labels, family='binomial') %>% summary()
```

**No effects for "incompatible".**

## Categorization

Whether participants use “if”, “when”, “in case”, “unless” to separate types of stones, and if so, whether such categorization is applied on the Active stone (A), Inactive stone (R), or both.

```{r echo=FALSE}
ggplot(labels, aes(x=rule_change_cond, fill=categorization)) + 
  geom_bar(stat="count", position="fill") +
  facet_grid(~fix_cond, switch = "x", scales = "free_x", space = "free_x") +
  theme(panel.spacing = unit(0, "lines"), 
        strip.background = element_blank(),
        strip.placement = "outside") +
  labs(x='', y='', title='Rule type') +
  scale_fill_brewer(palette="Paired")
```

```{r}
glm(categorization!='' ~ fix + rule_change, 
    data=labels, family='binomial') %>% summary() 

glm(categorization!=''~ fix + rule_change + fix * rule_change, 
    data=labels, family='binomial') %>% summary() 
```

### Rule type and categorization

|                  | True_rule | Vague   |
|------------------|-----------|---------|
| Categorization F | Exact     | Broad   |
| Categorization T | Redundant | Complex |

```{r echo=FALSE}
mix<-labels %>%
  filter(rule_like==1 & rule_type!='incompatible') %>%
  mutate(mix_type=case_when(
    categorization!='' & grepl('true', rule_type) ~ 'redundant',
    categorization!='' & rule_type=='vague' ~ 'complex',
    categorization=='' & grepl('true', rule_type) ~ 'exact',
    categorization=='' & rule_type=='vague' ~ 'broad',
    T ~ '')) %>%
  filter(mix_type!='') %>%
  mutate(mix_type=factor(mix_type, levels=c('exact', 'redundant', 'broad', 'complex')))

ggplot(data = mix, aes(x=rule_change_cond, fill = mix_type)) + 
  geom_bar(stat = "count", position = 'fill') +
  facet_grid(~fix_cond, switch = "x", scales = "free_x", space = "free_x") +
  theme(panel.spacing = unit(0, "lines"), 
        strip.background = element_blank(),
        strip.placement = "outside") +
  labs(x='', y='', title='Rule type x categorization') +
  scale_fill_brewer(palette="Paired")

```

```{r}
glm(mix_type=='complex' ~ fix + rule_change, 
    data=mix, family='binomial') %>% summary()

glm(mix_type=='complex' ~ fix + rule_change + fix * rule_change, 
    data=mix, family='binomial') %>% summary()
```

**No effects for other rule types.**


## Feature sources

For the result stone M, reference its feature change(s):

- **A**: with respect to the Active stone
- **R**: with respect to the Inactive stone
- **Constant**: a particular value in all cases
- **Multiple**: particular values case by case
- **General**: a broad description such as the feature simply “changes”
- **Unstated**: leave the feature unmentioned

```{r echo=FALSE}

vfeats<-bind_rows(
  labels %>% filter(rule_type=='vague') %>% 
    select(ix, condition, source=shade, fix_cond, rule_change_cond) %>%
    mutate(feature='edge'),
  labels %>% filter(rule_type=='vague') %>% 
    select(ix, condition, source=edge, fix_cond, rule_change_cond) %>%
    mutate(feature='shade')
) %>%
  mutate(source=factor(source, levels = c(
    'A', 'R', 'constant', 'multiple', 'general', 'unstated'
  )))


ggplot(vfeats, aes(x=rule_change_cond, fill=source)) + 
  geom_bar(stat="count", position = 'fill') +
  facet_grid(fix_cond~feature, switch = "x", scales = "free_x", space = "free_x") +
  theme(panel.spacing = unit(0, "lines"), 
        strip.background = element_blank(),
        strip.placement = "outside") +
  labs(x='', y='', title='M feature reference') +
  scale_fill_brewer(palette="Paired")

```

# Model fitting results

```{r include=FALSE}
library(GA)

load("../data/results/rdata_2/dpa_2.Rdata")
load("../data/results/rdata_2/dpr_2.Rdata")
load("../data/results/rdata_2/dpar_2.Rdata")

load("../data/results/rdata_2/dpa_pass_2.Rdata")
load("../data/results/rdata_2/dpr_pass_2.Rdata")
load("../data/results/rdata_2/dpar_pass_2.Rdata")

alphas<-c(1:10, 2^(4:10))
betas<-c(seq(0,1,.1), 2^(1:10))
```

Models: DP(A), DP(R), DP(AR)

**Consider a mixture model DP(A|R) with respect to the condition?**

Fitted parameters:

- alpha = `r alphas`
- beta = `r betas`
- inverse temperature `b`: higher => more confidence


## Model fits

### On all data points (N=102)

| Model           | Log likelihood | BIC      | Parameters               |
|-----------------|----------------|----------|--------------------------|
| Random baseline | -4889          | 9682     |                          |
| Non-DP          | -3706          | 7422     | b=3.19                   |
| DP(A)           | -3515          | 7043     | alpha=9, beta=256, b=9.5 |
| DP(R)           | -3460          | 6933     | alpha=5, beta=0, b=8.4   |
| **DP(AR)**      | **-3453**      | **6920** | alpha=5, beta=0.4, b=8.3 |

### On people that pass both check trials (N=53)

| Model           | Log likelihood | BIC      | Parameters                 |
|-----------------|----------------|----------|----------------------------|
| Random baseline | -2540          | 5081     |                            |
| Non-DP          | -1547          | 3102     | b=3.9                      |
| **DP(A)**       | **-1365**      | **2742** | alpha=5, beta=0.4, b=10.9  |
| DP(R)           | -1403          | 2818     | alpha=10, beta=0.6, b=12.6 |
| DP(AR)          | -1405          | 2822     | alpha=10, beta=512, b=12.5 |


## Sensitivity plots
```{r include=FALSE}
read_ll<-function(df, colname, default=0) {
  fits<-matrix(nrow=length(alphas), ncol=length(betas))
  for (i in 1:length(alphas)) {
    for (j in 1:length(betas)) {
      ll_col<-filter(df, alpha==alphas[i], beta==betas[j])
      ll_val<-if (nrow(ll_col)>0) ll_col[, colname] else default
      fits[i,j]<-if (ll_val > 0) -ll_val else ll_val
    }
  }
  return(fits)
}
```


Raw likelihood on 102 participants
```{r echo=FALSE, warning=FALSE}
par(mfrow=c(1,3))
persp3D(log(alphas), log(betas), read_ll(dpa_grid_2, 'raw_ll', 0), 
        theta=20, phi=20, expand=1, 
        xlab="log(alpha)", ylab="log(beta)", zlab="", main='DP(A)')
persp3D(log(alphas), log(betas), read_ll(dpr_grid_2, 'raw_ll', 0), 
        theta=20, phi=20, expand=1, 
        xlab="log(alpha)", ylab="log(beta)", zlab="", main='DP(R)')
persp3D(log(alphas), log(betas), read_ll(dpar_grid_2, 'raw_ll', 0), 
        theta=20, phi=20, expand=1, 
        xlab="log(alpha)", ylab="log(beta)", zlab="", main='DP(AR)')
```


Fitted likelihood on 102 participants
```{r echo=FALSE, warning=FALSE}
par(mfrow=c(1,3))
persp3D(log(alphas), log(betas), read_ll(dpa_grid_2, 'fitted_ll', 0), 
        theta=20, phi=20, expand=1, 
        xlab="log(alpha)", ylab="log(beta)", zlab="", main='DP(A)')
persp3D(log(alphas), log(betas), read_ll(dpr_grid_2, 'fitted_ll', 0), 
        theta=20, phi=20, expand=1, 
        xlab="log(alpha)", ylab="log(beta)", zlab="", main='DP(R)')
persp3D(log(alphas), log(betas), read_ll(dpar_grid_2, 'fitted_ll', 0), 
        theta=20, phi=20, expand=1, 
        xlab="log(alpha)", ylab="log(beta)", zlab="", main='DP(AR)')
```



Raw likelihood on 53 pass-check-trials participants
```{r echo=FALSE, warning=FALSE}
par(mfrow=c(1,3))
persp3D(log(alphas), log(betas), read_ll(dpa_pass_grid_2, 'raw_ll', 0), 
        theta=20, phi=20, expand=1, 
        xlab="log(alpha)", ylab="log(beta)", zlab="", main='DP(A)')
persp3D(log(alphas), log(betas), read_ll(dpr_pass_grid_2, 'raw_ll', 0), 
        theta=20, phi=20, expand=1, 
        xlab="log(alpha)", ylab="log(beta)", zlab="", main='DP(R)')
persp3D(log(alphas), log(betas), read_ll(dpar_pass_grid_2, 'raw_ll', 0), 
        theta=20, phi=20, expand=1, 
        xlab="log(alpha)", ylab="log(beta)", zlab="", main='DP(AR)')
```


Fitted likelihood on 53 pass-check-trials participants
```{r echo=FALSE, warning=FALSE}
par(mfrow=c(1,3))
persp3D(log(alphas), log(betas), read_ll(dpa_pass_grid_2, 'fitted_ll', 0), 
        theta=20, phi=20, expand=1, 
        xlab="log(alpha)", ylab="log(beta)", zlab="", main='DP(A)')
persp3D(log(alphas), log(betas), read_ll(dpr_pass_grid_2, 'fitted_ll', 0), 
        theta=20, phi=20, expand=1, 
        xlab="log(alpha)", ylab="log(beta)", zlab="", main='DP(R)')
persp3D(log(alphas), log(betas), read_ll(dpar_pass_grid_2, 'fitted_ll', 0), 
        theta=20, phi=20, expand=1, 
        xlab="log(alpha)", ylab="log(beta)", zlab="", main='DP(AR)')
```

# Other ideas

- Classify participant *selections*, not free responses, of causal rules (equivalent classed)

- This 2 x 2 design leads to a different 2 x 2 interpretation: instead of evaluating the underlying causal rule as changes to A's shade + 1 etc, it could also be interpreted as something like this

  |                         | Fix A | Fix R |
  |-------------------------|-------|-------|
  | M constant edge change  | A1    | A3    |
  | M constant shade change | A4    | A2    |

  This seems to have a effect on the causal relations that people conclude: the causal relation is shaped by both the cause and the effect. Our DP model so far focus on deliberating over causes, but it seems people also take a lot of info from the Result itself to construct their causal understanding of what's going on.
  







